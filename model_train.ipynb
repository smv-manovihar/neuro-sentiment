{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12192373,"sourceType":"datasetVersion","datasetId":7679755}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom nltk.tokenize import word_tokenize\nfrom nltk import bigrams\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (\n    Embedding,\n    SimpleRNN,\n    LSTM,\n    Bidirectional,\n    Dense,\n    Dropout,\n)\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tabulate import tabulate\nfrom sklearn.utils.class_weight import compute_class_weight","metadata":{"id":"2fd2ea23","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:31:46.501840Z","iopub.execute_input":"2025-06-17T07:31:46.502059Z","iopub.status.idle":"2025-06-17T07:32:04.451785Z","shell.execute_reply.started":"2025-06-17T07:31:46.502037Z","shell.execute_reply":"2025-06-17T07:32:04.451230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nltk.download(\"punkt\")\nnltk.download(\"punkt_tab\")\nnltk.download(\"stopwords\")\nnltk.download(\"wordnet\")","metadata":{"id":"a0484a37","outputId":"e40048c9-e9f1-4d88-b0d7-9dae76d37289","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:04.452954Z","iopub.execute_input":"2025-06-17T07:32:04.453453Z","iopub.status.idle":"2025-06-17T07:32:04.775422Z","shell.execute_reply.started":"2025-06-17T07:32:04.453434Z","shell.execute_reply":"2025-06-17T07:32:04.774816Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_data():\n    df = pd.read_csv(\"/kaggle/input/flipkart-product/flipkart_product.csv\", encoding=\"ISO-8859-1\")\n    df = df[[\"Summary\", \"Rate\"]].dropna()\n    df.columns = [\"review\", \"rating\"]\n    df[\"rating\"] = df[\"rating\"].astype(str).str.extract(\"(\\d+)\")\n    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n    df = df.dropna(subset=[\"rating\"])\n    df[\"rating\"] = df[\"rating\"].astype(int)\n\n    def rate_to_sentiment(rate):\n        if rate >= 4:\n            return \"positive\"\n        elif rate == 3:\n            return \"neutral\"\n        else:\n            return \"negative\"\n\n    df[\"sentiment\"] = df[\"rating\"].apply(rate_to_sentiment)\n    return df\n\n\ndef preprocess_text(text):\n    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", str(text).lower())\n    lemmatizer = WordNetLemmatizer()\n    stop_words = set(stopwords.words(\"english\"))\n    tokens = word_tokenize(str(text).lower())\n    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]\n    tokens = [token for token in tokens if token not in stop_words]\n    return \" \".join(tokens)\n\n\n# Making every sentiment have same number of entries\ndef balance_dataset(df):\n    min_count = df[\"sentiment\"].value_counts().min()\n    balanced_df = pd.concat(\n        [\n            df[df[\"sentiment\"] == \"positive\"].sample(min_count, random_state=42),\n            df[df[\"sentiment\"] == \"neutral\"].sample(min_count, random_state=42),\n            df[df[\"sentiment\"] == \"negative\"].sample(min_count, random_state=42),\n        ]\n    )\n    return balanced_df","metadata":{"id":"fefa93d6","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:04.776059Z","iopub.execute_input":"2025-06-17T07:32:04.776321Z","iopub.status.idle":"2025-06-17T07:32:04.783771Z","shell.execute_reply.started":"2025-06-17T07:32:04.776303Z","shell.execute_reply":"2025-06-17T07:32:04.783018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = load_data()\nprint(df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:04.784440Z","iopub.execute_input":"2025-06-17T07:32:04.784611Z","iopub.status.idle":"2025-06-17T07:32:06.151949Z","shell.execute_reply.started":"2025-06-17T07:32:04.784596Z","shell.execute_reply":"2025-06-17T07:32:06.151320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"cleaned_review\"] = df[\"review\"].apply(preprocess_text)","metadata":{"id":"788531d7","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:06.153910Z","iopub.execute_input":"2025-06-17T07:32:06.154136Z","iopub.status.idle":"2025-06-17T07:32:45.441607Z","shell.execute_reply.started":"2025-06-17T07:32:06.154118Z","shell.execute_reply":"2025-06-17T07:32:45.440734Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:45.442475Z","iopub.execute_input":"2025-06-17T07:32:45.442716Z","iopub.status.idle":"2025-06-17T07:32:45.448306Z","shell.execute_reply.started":"2025-06-17T07:32:45.442695Z","shell.execute_reply":"2025-06-17T07:32:45.447652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_map = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\ndf[\"label\"] = df[\"sentiment\"].map(label_map)\nlabel_map_reverse = {v: k for k, v in label_map.items()}","metadata":{"id":"c5327a03","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:45.449114Z","iopub.execute_input":"2025-06-17T07:32:45.449371Z","iopub.status.idle":"2025-06-17T07:32:45.476678Z","shell.execute_reply.started":"2025-06-17T07:32:45.449351Z","shell.execute_reply":"2025-06-17T07:32:45.475933Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenization and padding\nmax_words = 10000\nmax_len = 100\ntokenizer = Tokenizer(num_words=max_words)\ntokenizer.fit_on_texts(df[\"cleaned_review\"])\nsequences = tokenizer.texts_to_sequences(df[\"cleaned_review\"])\npadded_sequences = pad_sequences(sequences, maxlen=max_len)","metadata":{"id":"048f407a","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:45.477378Z","iopub.execute_input":"2025-06-17T07:32:45.477601Z","iopub.status.idle":"2025-06-17T07:32:48.849438Z","shell.execute_reply.started":"2025-06-17T07:32:45.477582Z","shell.execute_reply":"2025-06-17T07:32:48.848656Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = padded_sequences\ny = to_categorical(df[\"label\"], num_classes=3)\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)","metadata":{"id":"e8dd0845","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:48.850291Z","iopub.execute_input":"2025-06-17T07:32:48.850527Z","iopub.status.idle":"2025-06-17T07:32:48.917448Z","shell.execute_reply.started":"2025-06-17T07:32:48.850501Z","shell.execute_reply":"2025-06-17T07:32:48.916764Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def build_rnn_model():\n    model = Sequential(\n        [\n            Embedding(max_words, 400, input_length=max_len),\n            SimpleRNN(256, return_sequences=False, kernel_regularizer=l2(0.01)),\n            Dense(\n                64, activation=\"relu\", kernel_regularizer=l2(0.01)\n            ),  # Increased units\n            Dropout(0.6),  # Increased dropout\n            Dense(3, activation=\"softmax\"),\n        ]\n    )\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"],\n    )\n    return model\n\n\ndef build_lstm_model():\n    model = Sequential(\n        [\n            Embedding(max_words, 400, input_length=max_len),\n            LSTM(256, return_sequences=False, kernel_regularizer=l2(0.01)),\n            Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)),\n            Dropout(0.6),\n            Dense(3, activation=\"softmax\"),\n        ]\n    )\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"],\n    )\n    return model\n\n\ndef build_bilstm_model():\n    model = Sequential(\n        [\n            Embedding(max_words, 400, input_length=max_len),\n            Bidirectional(\n                LSTM(256, return_sequences=False, kernel_regularizer=l2(0.01))\n            ),\n            Dense(64, activation=\"relu\", kernel_regularizer=l2(0.01)),\n            Dropout(0.6),\n            Dense(3, activation=\"softmax\"),\n        ]\n    )\n    model.compile(\n        optimizer=Adam(learning_rate=0.0001),\n        loss=\"categorical_crossentropy\",\n        metrics=[\"accuracy\"],\n    )\n    return model","metadata":{"id":"0633de06","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:48.918334Z","iopub.execute_input":"2025-06-17T07:32:48.918544Z","iopub.status.idle":"2025-06-17T07:32:48.926778Z","shell.execute_reply.started":"2025-06-17T07:32:48.918527Z","shell.execute_reply":"2025-06-17T07:32:48.926076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models = {\n    \"RNN\": build_rnn_model(),\n    \"LSTM\": build_lstm_model(),\n    \"BiLSTM\": build_bilstm_model(),\n}\nhistories = {}\nresults = {}\nearly_stopping = EarlyStopping(\n    monitor=\"val_loss\", patience=3, restore_best_weights=True\n)\n# Compute class weights based on the labels\nclass_weights = compute_class_weight(\n    \"balanced\", classes=np.unique(df[\"label\"]), y=df[\"label\"]\n)\nclass_weights_dict = dict(enumerate(class_weights))\nprint(\"Class Weights:\", class_weights_dict)\n\n# Update the training loop to include class weights\nfor name, model in models.items():\n    print(f\"Training {name}...\")\n    history = model.fit(\n        X_train,\n        y_train,\n        epochs=20,\n        batch_size=32,\n        validation_split=0.2,\n        callbacks=[early_stopping],\n        class_weight=class_weights_dict,\n        verbose=1,\n    )\n    histories[name] = history.history\n    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n    results[name] = {\"loss\": loss, \"accuracy\": accuracy}\n    print(f\"{name} Test Accuracy: {accuracy:.4f}\")\n\n    y_pred = model.predict(X_test, verbose=0)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_test_classes = np.argmax(y_test, axis=1)\n\n    cm = confusion_matrix(y_test_classes, y_pred_classes)\n    plt.figure(figsize=(4, 3))\n    sns.heatmap(\n        cm,\n        annot=True,\n        fmt=\"d\",\n        cmap=\"Blues\",\n        xticklabels=[\"Negative\", \"Neutral\", \"Positive\"],\n        yticklabels=[\"Negative\", \"Neutral\", \"Positive\"],\n    )\n    plt.title(f\"Confusion Matrix - {name}\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"True\")\n    plt.show()","metadata":{"id":"c0ef0fcb","outputId":"d2fdd458-49fa-4deb-9436-7c12ed7298ef","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T07:32:48.927543Z","iopub.execute_input":"2025-06-17T07:32:48.927710Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pickle\n\n# Directory where Kaggle allows writing\nsave_dir = \"/kaggle/working/saved_models\"\nos.makedirs(save_dir, exist_ok=True)\n\n# Save models\nfor name, model in models.items():\n    model.save(os.path.join(save_dir, f\"{name}_model.h5\"))\n\n# Save tokenizer\nwith open(os.path.join(save_dir, \"tokenizer.pkl\"), \"wb\") as f:\n    pickle.dump(tokenizer, f)\n\n# Save label maps\nwith open(os.path.join(save_dir, \"label_maps.pkl\"), \"wb\") as f:\n    pickle.dump({\"label_map\": label_map, \"label_map_reverse\": label_map_reverse}, f)\n\nprint(\"Models and tokenizer saved to /kaggle/working/saved_models/\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot validation accuracy and loss\nplt.figure(figsize=(10, 6))\nfor name, history in histories.items():\n    plt.plot(history[\"val_accuracy\"], label=f\"{name} Val Accuracy\")\nplt.title(\"Model Validation Accuracy Comparison\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Accuracy\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(10, 6))\nfor name, history in histories.items():\n    plt.plot(history[\"val_loss\"], label=f\"{name} Val Loss\")\nplt.title(\"Model Validation Loss Comparison\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"id":"1edcdf63","outputId":"6409cec1-7863-4955-e9fa-51b07e2a8ad6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, model in models.items():\n    y_pred = model.predict(X_test, verbose=0)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_test_classes = np.argmax(y_test, axis=1)\n    print(f\"\\nClassification Report for {name}:\")\n    print(\n        classification_report(\n            y_test_classes,\n            y_pred_classes,\n            target_names=[\"Negative\", \"Neutral\", \"Positive\"],\n        )\n    )","metadata":{"id":"a6defa80","outputId":"38964dfb-1f4f-441c-a216-696118c92593","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict unseen data\ndef predict_unseen_data(models, tokenizer, reviews, max_len=150):\n    cleaned_reviews = [preprocess_text(review) for review in reviews]\n    sequences = tokenizer.texts_to_sequences(cleaned_reviews)\n    padded = pad_sequences(sequences, maxlen=max_len)\n    predictions = {}\n    for name, model in models.items():\n        probs = model.predict(padded, verbose=0)\n        predicted_classes = np.argmax(probs, axis=1)\n        predictions[name] = list(zip(predicted_classes, probs))\n    return predictions\n\n\nunseen_reviews = [\n    \"This product is fantastic and works perfectly!\",\n    \"Absolutely terrible, broke after one use.\",\n    \"It's okay, nothing special but gets the job done.\",\n]\nprint(\"\\nPredicting sentiments for unseen reviews:\")\npredictions = predict_unseen_data(models, tokenizer, unseen_reviews, max_len)\n\nfor i, review in enumerate(unseen_reviews):\n    print(f\"\\nReview: {review}\")\n    for model_name, preds in predictions.items():\n        pred_class, pred_probs = preds[i]\n        sentiment = label_map_reverse[pred_class]\n        probs_str = \", \".join(\n            [f\"{label_map_reverse[j]}: {prob:.4f}\" for j, prob in enumerate(pred_probs)]\n        )\n        print(f\"{model_name} Prediction: {sentiment} ({probs_str})\")","metadata":{"id":"29b3e0c0","outputId":"f53f44dd-0088-42b3-b2dc-c50aa3de45f0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Performance table\nperformance_table = []\nfor i, (name, model) in enumerate(models.items(), 1):\n    loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n    y_pred = model.predict(X_test, verbose=0)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_test_classes = np.argmax(y_test, axis=1)\n    report = classification_report(y_test_classes, y_pred_classes, output_dict=True)\n    f1_score = report[\"macro avg\"][\"f1-score\"]\n    performance_table.append([i, name, f\"{accuracy:.2f}\", f\"{f1_score:.2f}\"])\n\nprint(\"\\nPerformance Table:\")\nheaders = [\"S.No\", \"Type of Model\", \"Accuracy\", \"F1-Score\"]\nprint(tabulate(performance_table, headers=headers, tablefmt=\"grid\")","metadata":{"id":"w5ze-3kwcpLh","outputId":"bd0cb584-e925-410c-f543-9136b95aba09","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}